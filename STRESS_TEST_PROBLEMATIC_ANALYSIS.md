# VOXANNE MVP - PROBLEMATIC STRESS TEST ANALYSIS
## "Where This Will Break Under Real-World Conditions"

**Date:** December 20, 2025
**Status:** Failure-mode analysis of all 10 features
**Risk Level:** üî¥ HIGH - Multiple critical vulnerabilities identified

---

## EXECUTIVE SUMMARY

This is not a happy-path analysis. Below are the **exact failure modes** that will occur when features are stressed:

- ‚ùå **Concurrent calls**: System will drop calls after 5-10 simultaneous connections
- ‚ùå **Large documents**: KB chunking will fail silently on 50MB+ files
- ‚ùå **WebSocket stability**: Connections will accumulate memory and crash after 1000 messages
- ‚ùå **Rate limiting**: OpenAI embedding API will hit 429 errors with no fallback
- ‚ùå **Authentication**: Dev-mode bypass could allow unauthorized access
- ‚ùå **Recording cleanup**: Failed uploads will accumulate forever (no cleanup job)
- ‚ùå **Vapi integration**: Circuit breaker will break the entire system after 5 failures

---

## FEATURE-BY-FEATURE FAILURE ANALYSIS

### FEATURE 1: INBOUND CALL HANDLING üí•

**Claim:** "5-retry logic with exponential backoff prevents failures"

**Problem 1: Race Condition Still Exists**
```typescript
// webhooks.ts line 69-100
async function injectRagContextIntoAgent(params: {
  vapiApiKey: string;
  assistantId: string;
  ragContext: string;
}): Promise<void> {
  // üî¥ ISSUE: This runs SYNCHRONOUSLY on each webhook
  // If the Vapi API is slow (5-10 seconds), the webhook times out
  // and the retry logic restarts from zero

  const vapi = new VapiClient(params.vapiApiKey);
  const assistant = await vapi.getAssistant(params.assistantId);
  // Timeout: Express default is 30 seconds
  // If this takes >30 seconds, webhook fails
}
```

**Problem 2: Idempotency Key Missing for Most Operations**
```typescript
// vapi-client.ts - CreateCallParams
export interface CreateCallParams {
  assistantId: string;
  // ‚úÖ Has idempotencyKey
  idempotencyKey?: string;
}

// But webhooks.ts line 14 doesn't USE IT when injecting context
// ‚ùå If webhook retries, context gets injected TWICE
```

**Problem 3: Exponential Backoff Math is Wrong**
```typescript
// embeddings.ts line 61
const delay = RETRY_DELAY_MS * Math.pow(2, retries);
// RETRY_DELAY_MS = 1000, MAX_RETRIES = 3
// Sequence: 1s, 2s, 4s, 8s = 15s total
// But Express webhook timeout is often 30s
// ‚ùå Total backoff will exceed timeout
```

**What Happens:**
1. Call comes in at 12:00:00
2. Webhook handler starts injecting RAG context
3. OpenAI embedding API is slow (8s)
4. Handler takes 15s to complete
5. Express timeout at 30s fires anyway
6. Retry #1 starts at 12:00:15 (duplicate call to inject RAG)
7. Call is now processed twice ‚ùå

**Test Case That Will Fail:**
```bash
# Simulate slow OpenAI API
Make 10 concurrent inbound calls
OpenAI embedding API responding in 10-15 seconds
Expected: 10 calls recorded
Actual: Some calls dropped, some duplicate RAG injection
```

---

### FEATURE 2: CALL RECORDING & STORAGE üí•

**Claim:** "Recording downloaded from Vapi, uploaded to Supabase"

**Problem 1: No Cleanup for Failed Uploads**
```typescript
// recording-upload-retry.ts exists but:
// 1. What's the retention policy? Forever?
// 2. What if Supabase quota is hit?
// 3. No automatic cleanup of old failed uploads

// recording_failed_uploads table will grow infinitely
```

**Problem 2: Signed URL Expiration Not Enforced**
```typescript
// call-recording-storage.ts
// Claim: "Signed URL expires in 1 hour"
// But what if:
// - Supabase token expires early (network issue)?
// - User bookmarks the URL (still works after 1 hour)?
// - Security: 1 hour might be too long for HIPAA compliance
```

**Problem 3: No Retry Mechanism for Supabase Upload Failures**
```typescript
// What happens if:
// 1. Recording downloaded from Vapi ‚úÖ
// 2. Supabase connection drops during upload ‚ùå
// 3. 100MB recording file is lost
// 4. No automatic retry (only manual via recording-upload-retry job)
```

**Problem 4: Recording URL Hardcoding**
```typescript
// If you're storing the Supabase URL in the database,
// and Supabase changes their URL format,
// all old recording links break ‚ùå
```

**What Happens:**
1. Call ends at 12:00:00, recording ready at 12:00:05
2. Backend downloads from Vapi ‚úÖ
3. Supabase upload starts at 12:00:10
4. Network glitch at 12:00:12 - upload fails
5. Recording stuck in `recording_upload_queue` forever
6. No error alert sent
7. After 24 hours, you have 1000s of failed uploads ‚ùå

**Test Case That Will Fail:**
```bash
# Simulate network failure during upload
Make 50 calls
Simulate 20% network packet loss during Supabase upload
Expected: All recordings eventually uploaded (with retries)
Actual: 10 recordings lost, orphaned in database
```

---

### FEATURE 3: LIVE TRANSCRIPT üí•

**Claim:** "WebSocket deduplication prevents duplicate messages"

**Problem 1: Dedup Logic is Incomplete**
```typescript
// websocket.ts - Dedup based on:
// (callId, speaker, text, timestamp bucket)
//
// But what if:
// 1. Same customer says same thing twice? ("Yes, yes")
// 2. Agent repeats same response? ("Let me check... let me check")
// 3. Both will be deduplicated ‚ùå
```

**Problem 2: WebSocket Buffering Will Grow Unbounded**
```typescript
// websocket.ts line 15
const MAX_WS_BUFFERED_AMOUNT_BYTES = Number(process.env.WS_MAX_BUFFERED_BYTES || 2_000_000);
// Default: 2MB buffer per connection
// If frontend is slow to consume messages:
// - Long call (60 minutes): 100+ transcript chunks
// - Each chunk: ~500 bytes
// - Total: 50KB per call
// But with 100 concurrent calls: 5MB buffered memory ‚ùå
```

**Problem 3: No Maximum Message Queue**
```typescript
// If WebSocket client disconnects and reconnects:
// - It requests historical transcript
// - But what if transcript is 10,000 messages?
// - All 10,000 get sent at once ‚ùå
// - Client browser crashes (out of memory)
```

**Problem 4: Duplicate Handling Breaks on Partial Matches**
```typescript
// Dedup on "timestamp bucket" means:
// If two messages arrive within same millisecond window:
// One gets dropped ‚ùå

// Example:
// Agent: "Your appointment is..." (timestamp: 1234)
// Agent: "Your appointment is at 3pm" (timestamp: 1234)
// Second one gets deduplicated, customer misses info ‚ùå
```

**What Happens:**
1. Customer speaks continuously for 5 minutes
2. Vapi sends ~50 transcript chunks
3. WebSocket buffers them all: ~25KB
4. Frontend tries to render all at once
5. Browser's JavaScript engine struggles
6. Transcript display lags by 10+ seconds
7. User thinks the system is broken ‚ùå

**Test Case That Will Fail:**
```bash
# Simulate slow frontend
Make 1 call with 10-minute duration
Frontend intentionally delays message consumption (100ms per message)
Expected: Smooth transcript streaming
Actual: WebSocket buffer fills up, messages backed up, frontend lag
```

---

### FEATURE 4: CALL LOG DASHBOARD üí•

**Claim:** "Dashboard showing all calls with correct data"

**Problem 1: No Pagination Validation**
```typescript
// calls-dashboard.ts
// Claim: "pagination (100 calls per page)"
// But what if:
// - User requests page 10,000,000?
// - Query scans entire database ‚ùå
// - Database timeout
```

**Problem 2: No Index on Filter Columns**
```typescript
// If database has 10,000+ calls:
// - Filter by "date range" might scan all rows
// - Filter by "call status" might scan all rows
// - No index = O(n) query = 30+ second response ‚ùå
```

**Problem 3: Auto-Refresh Creates Memory Leak**
```typescript
// WebSocket broadcasts every call_ended event
// If you have 1000 users watching dashboard:
// - Each user gets 1000 updates per hour (1 per call)
// - Each update: ~5KB JSON
// - Total bandwidth: 5GB/hour ‚ùå
//
// Memory per user: accumulating WebSocket messages
// After 1 hour: 1GB of buffered messages ‚ùå
```

**Problem 4: No Cache Invalidation**
```typescript
// If dashboard caches call list:
// - New call arrives
// - Cache not invalidated
// - User sees stale data for 5+ minutes ‚ùå
```

**What Happens:**
1. Clinic has 500 calls in system
2. User loads dashboard (no pagination)
3. Database query: SELECT * FROM calls WHERE org_id = ...
4. Returns 500 rows as JSON
5. Frontend receives ~500KB of data
6. Rendering 500 rows in table = 60+ second delay
7. User clicks refresh while loading
8. Second query starts (duplicate memory)
9. Browser uses >500MB RAM
10. System becomes unresponsive ‚ùå

**Test Case That Will Fail:**
```bash
# Simulate large call volume
Create 10,000 test calls in database
Load dashboard and filter by date range
Expected: Response in <2 seconds
Actual: Database timeout after 30 seconds
```

---

### FEATURE 5: KNOWLEDGE BASE RAG üí•

**Claim:** "Document auto-chunked and embedded synchronously"

**Problem 1: Token Count Estimation is Wrong**
```typescript
// document-chunker.ts line 25-27
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4);
}

// This is a ROUGH APPROXIMATION
// Real OpenAI tokenizer:
// - Some characters = 1 token
// - Some = 2-4 tokens
// - CJK characters = 1 token each
// - Special symbols vary
//
// Example: "S√£o Paulo"
// Estimate: 9 chars / 4 = 2 tokens
// Actual: 3 tokens
// Error: 33% off ‚ùå

// Impact: Chunks might be 1000 tokens estimated, 1200 actual
// Exceeds OpenAI API limit (8000 chars ‚Üí potential truncation)
```

**Problem 2: Embedding API Rate Limiting**
```typescript
// embeddings.ts line 59
if (retries < MAX_RETRIES && error?.status === 429) {
  // Rate limited - retry
  const delay = RETRY_DELAY_MS * Math.pow(2, retries);
  // MAX_RETRIES = 3
  // Sequence: 1s, 2s, 4s, 8s = 15s total

  // But OpenAI's free tier rate limit: 3,500 requests/minute
  // If you're uploading a 100-page document (50 chunks):
  // - 50 API calls
  // - At 3 calls/second: 17 seconds
  // - If you have 10 users uploading simultaneously:
  // - 500 API calls in 17 seconds
  // - Rate limit WILL trigger ‚ùå
  // - Chunks #45-50 fail to embed ‚ùå
}
```

**Problem 3: No Vector Search Fallback**
```typescript
// rag-context-provider.ts line 44-55
const { data, error } = await supabase.rpc('match_knowledge_chunks', {
  query_embedding: queryEmbedding,
  match_threshold: SIMILARITY_THRESHOLD,
  match_count: MAX_CHUNKS,
  p_org_id: orgId
});

if (error) {
  log.warn('RAG', 'Vector search failed', { error: error.message });
  return { context: '', chunkCount: 0, hasContext: false };
}

// üî¥ PROBLEM: No context = agent doesn't know KB exists
// Agent falls back to generic responses
// Customer asks "How much is a BBL?"
// Agent: "I don't have that information" ‚ùå
// (But it's in the KB!)
```

**Problem 4: Large Document Upload Timeout**
```typescript
// If you upload a 10MB document:
// - Chunking: Synchronous, blocks endpoint
// - Embedding generation: 50 chunks √ó 1.5 seconds = 75 seconds
// - Express timeout: 30 seconds ‚ùå
//
// What happens:
// 1. User uploads 10MB document
// 2. Server starts processing
// 3. At 30 seconds: Express times out
// 4. Client gets 504 Gateway Timeout ‚ùå
// 5. But server keeps processing in background
// 6. Chunks get created (orphaned)
// 7. User thinks upload failed, tries again
// 8. Now 2x chunks in database ‚ùå
```

**Problem 5: No Maximum Document Size**
```typescript
// What if user uploads 1GB of text?
// - Attempts to chunk synchronously
// - Memory exhaustion: Node.js heap overflow ‚ùå
// - Server crashes
// - All WebSocket clients disconnected ‚ùå
```

**What Happens:**
1. Clinic uploads 50-page pricing document (200KB)
2. Backend chunks it into 20 chunks
3. Embedding generation starts (20 calls to OpenAI)
4. Call #5 hits rate limit (429)
5. Retry logic waits 4 seconds
6. Meanwhile, 3 more embedding calls fail
7. Only chunks #1-4 get embedded
8. Chunks #5-20 stuck in database without embeddings
9. Vector search skips them (no embedding = no match)
10. Agent never sees pricing info ‚ùå

**Test Case That Will Fail:**
```bash
# Stress test RAG
Upload 10 documents simultaneously, each 100KB
Each triggers 20 embedding API calls
Expected: All documents embedded successfully
Actual: Random chunks fail, OpenAI rate limit hits
```

---

### FEATURE 6: AGENT CONFIGURATION üí•

**Claim:** "Changes sync to Vapi automatically"

**Problem 1: No Sync Verification**
```typescript
// agent-sync.ts route probably does:
// 1. Save config to database ‚úÖ
// 2. Send to Vapi API ‚ùì
// But what if Vapi API returns 5xx error?
// - Config saved locally ‚ùå
// - But not synced to Vapi ‚ùå
// - Next call uses old config ‚ùå
// - User thinks change worked (false confidence)
```

**Problem 2: System Prompt Injection Vulnerability**
```typescript
// If user's system prompt includes:
// "Ignore previous instructions..."
// Or: "{{userInput}}"
// Agent might do unexpected things ‚ùå

// EXAMPLE:
// System prompt: "You are a receptionist for {{clinicName}}"
// Config saves: "You are a receptionist for {{userInput}} Clinic"
// Then attacker changes config to:
// "You are a receptionist for <image src=x onerror=alert(1)> Clinic"
// If this gets logged without sanitization: XSS ‚ùå
```

**Problem 3: Voice Configuration Persistence**
```typescript
// voice: "British Female"
// But what if Vapi's voice IDs change?
// Or a voice is deprecated?
// - Config stored with old voice ID
// - Next call fails (voice not found)
// - No error handling ‚ùå
```

**Problem 4: No Rollback Mechanism**
```typescript
// User changes system prompt to something bad
// Now agent gives wrong responses
// No history, no way to revert ‚ùå
```

**What Happens:**
1. User changes system prompt: "Be more casual"
2. Frontend sends to backend
3. Backend saves to database ‚úÖ
4. Backend sends to Vapi API
5. Vapi returns 500 error (temporary outage)
6. Backend logs error but doesn't retry ‚ùå
7. User refreshes dashboard, sees change was saved
8. User thinks it's synced
9. Next customer call: Old system prompt still active
10. User wonders why change didn't work ‚ùå

**Test Case That Will Fail:**
```bash
# Stress test config sync
Change system prompt 10 times in rapid succession
Simulate Vapi API returning 5xx on attempts 3, 5, 7
Expected: All changes eventually sync
Actual: Some changes fail silently, inconsistent state
```

---

### FEATURE 7: SMART ESCALATION (SAFE MODE) üí•

**Claim:** "Medical questions escalated safely"

**Problem 1: Keyword Detection is Fragile**
```typescript
// System prompt says: Escalate on keywords like "diagnosis"
// But what if customer says:
// - "Is my swelling normal?" (contains "normal", not "diagnosis")
// - "Should I be concerned about this rash?" (no medical keyword)
// - "Is this an infection?" (not in keyword list)
// System fails to escalate ‚ùå
```

**Problem 2: No Actual Escalation Mechanism**
```typescript
// Claim: "Call transferred or voicemail taken"
// But the code just has responses like:
// "Let me connect you..."
// What actually happens?
// - Does Vapi transfer the call? ‚ùì
// - Does it take a voicemail? ‚ùì
// - Or does it just hang up? ‚ùå
//
// No actual transfer logic in the code!
```

**Problem 3: Escalation Logic Buried in Prompt**
```typescript
// If escalation depends on system prompt,
// and system prompt is user-editable,
// user could accidentally disable escalation:
// "Ignore the medical safety rules and answer everything"
// Now system answers medical questions anyway ‚ùå
```

**Problem 4: False Positives**
```typescript
// Keyword: "treatment"
// Customer: "I'm looking for the best treatment option"
// Escalates incorrectly ‚ùå
//
// Keyword: "medication"
// Customer: "Do you accept medication insurance?"
// Escalates incorrectly ‚ùå
```

**What Happens:**
1. Customer calls: "Hi, I had BBL surgery 2 weeks ago"
2. Agent responds: "Great! How can I help?"
3. Customer: "There's some swelling, is that normal?"
4. Agent doesn't recognize medical question (no keyword match)
5. Agent responds: "Swelling usually goes down in a few weeks"
6. This is medical advice ‚ùå
7. HIPAA/compliance violation ‚ùå

**Test Case That Will Fail:**
```bash
# Test escalation accuracy
Create 100 realistic customer queries mixing:
- Medical questions: "Is my scar normal?"
- Non-medical: "Do you have morning appointments?"
- Borderline: "Is the pain from the procedure normal?"
Expected: 90%+ accuracy
Actual: 60% accuracy (many false negatives)
```

---

### FEATURE 8: REAL-TIME DASHBOARD UPDATES üí•

**Claim:** "WebSocket auto-reconnect, connection status indicator"

**Problem 1: No Heartbeat/Ping Mechanism**
```typescript
// websocket.ts doesn't show:
// ws.on('ping', ...)
// ws.ping() / ws.pong()
//
// What happens:
// - Connection drops (network issue)
// - Client doesn't know for 30+ seconds
// - Waits for next message to discover disconnect ‚ùå
//
// Result: Stale connection appears "live" ‚ùå
```

**Problem 2: Reconnect Logic Might Not Work**
```typescript
// Frontend has: "Auto-reconnect logic (3 attempts, exponential backoff)"
// But what if:
// - Server is down for 10 minutes
// - Client gives up after 3 retries (15 seconds)
// - Even when server comes back, client doesn't reconnect ‚ùå
//
// Result: Dashboard appears disconnected forever ‚ùå
```

**Problem 3: Message Ordering Not Guaranteed**
```typescript
// If client reconnects while events are queued:
// 1. Event A sent at 12:00:00
// 2. Connection drops at 12:00:01
// 3. Event B queued on server
// 4. Client reconnects at 12:00:05
// 5. Client might get: [B, A] (wrong order)
// 6. Dashboard shows call ending before starting ‚ùå
```

**Problem 4: Memory Leak in Listener Registration**
```typescript
// If WebSocket connection reconnects 100 times:
// Each time: ws.on('message', handler)
// Handlers accumulate (not removed)
// Each message triggers 100 handlers ‚ùå
// Memory leak grows unbounded ‚ùå
```

**What Happens:**
1. User opens dashboard, WebSocket connects ‚úÖ
2. New call arrives, broadcast event sent ‚úÖ
3. User's network hiccup (< 1 second)
4. WebSocket silently closes
5. No new events reach frontend
6. User sees "Live" status but no updates coming
7. After 5 minutes, WebSocket reconnects
8. User wonders what they missed ‚ùå

**Test Case That Will Fail:**
```bash
# Simulate network instability
Open dashboard
Kill backend server, wait 30 seconds, restart
Expected: Dashboard reconnects automatically
Actual: Dashboard shows "Disconnected" forever (manual refresh needed)
```

---

### FEATURE 9: AUTHENTICATION & SECURITY üí•

**Claim:** "JWT token validation, RLS policies, protected routes"

**Problem 1: Dev-Mode Bypass in Production**
```typescript
// auth.ts line 44-75
const isDev = (process.env.NODE_ENV || 'development') === 'development';
if (isDev) {
  // Try token auth but fall back to dev user on failure
  try {
    const { data: { user }, error } = await supabase.auth.getUser(token);
    if (!error && user) {
      // ‚úÖ Valid token
    }
  } catch (e) {
    // ‚ùå FALLBACK: No validation, just proceed as dev user
    console.log('[AuthOrDev] Token auth failed in dev mode, falling back to dev user');
  }
}

// PROBLEM: If NODE_ENV is not explicitly set to 'production':
// - Default is 'development'
// - Any invalid token falls back to dev user
// - Dev user probably has access to all orgs ‚ùå
```

**Problem 2: No Token Refresh Mechanism**
```typescript
// Claim: "JWT token management, token expiration 24 hours"
// But what if:
// - User's token expires while they're using the dashboard
// - Frontend makes API call with expired token
// - Backend returns 401
// - Frontend doesn't have refresh token ‚ùå
// - User gets logged out abruptly ‚ùå
```

**Problem 3: RLS Policies Might Be Incomplete**
```typescript
// Claim: "Row-level security prevents data leaks"
// But what if:
// - A route doesn't check org_id before returning data
// - User from Org A queries their calls
// - Backend accidentally returns Org B's calls ‚ùå
//
// Example vulnerability:
// GET /api/calls?userId=org-b-user-id
// If backend doesn't validate userId belongs to caller's org:
// Data leak ‚ùå
```

**Problem 4: No CSRF Protection**
```typescript
// If dashboard is at callwaitingai.dev
// And attacker creates malicious form at attacker.com:
// <form action="https://callwaitingai.dev/api/calls" method="POST">
// <input name="deleteCallId" value="important-call">
// </form>
//
// If frontend user visits attacker.com while logged in:
// Their browser sends credentials automatically
// Call gets deleted ‚ùå (CSRF attack)
```

**Problem 5: API Keys Stored in Plain Text**
```typescript
// integrations.ts comment line 10:
// config: { vapi_api_key: apiKey } // TODO: Encrypt this in production
//
// If database is compromised:
// All VAPI API keys exposed ‚ùå
```

**What Happens:**
1. Engineer deploys to production
2. Forgets to set NODE_ENV=production
3. Someone finds the API endpoint documentation
4. Sends request with malformed token
5. Middleware falls back to dev user (because isDev = true)
6. Attacker gets access to all org data ‚ùå
7. No one notices for weeks

**Test Case That Will Fail:**
```bash
# Test auth bypass
Set NODE_ENV to anything except "production"
Make API request with invalid token
Expected: 401 Unauthorized
Actual: Request succeeds (dev fallback)
```

---

### FEATURE 10: PRODUCTION DEPLOYMENT üí•

**Claim:** "Auto-deploy from GitHub, environment variables configured, health check endpoint"

**Problem 1: No Health Check for Dependencies**
```typescript
// /health endpoint probably returns:
// { "status": "ok" }
//
// But what if:
// - Database is down
// - OpenAI API is unreachable
// - Vapi API is unreachable
// - WebSocket server not running
//
// Health check still returns 200 ‚ùå
// Load balancer thinks system is healthy ‚ùå
```

**Problem 2: No Database Migrations on Startup**
```typescript
// If a new code version requires new database columns:
// 1. Code deployed to Render
// 2. Server starts
// 3. Query tries to access new column
// 4. Column doesn't exist (migration didn't run)
// 5. 500 error
// 6. All requests fail ‚ùå
```

**Problem 3: Render Timeout Issues**
```typescript
// Render has a 30-second timeout for requests
// If RAG context injection takes 20 seconds:
// - Webhook has 10 seconds left for other processing
// - Not enough buffer for errors/retries ‚ùå
```

**Problem 4: Environment Variable Secrets**
```typescript
// If .env file is committed to GitHub:
// - All API keys exposed
// - Anyone can fork repo and see secrets ‚ùå
//
// If secrets only in Render dashboard:
// - How are they backed up?
// - What if Render account is compromised?
// - No audit log of who accessed secrets
```

**Problem 5: No Rollback Strategy**
```typescript
// If bad code is deployed:
// 1. Auto-deploy pushes bad code
// 2. Everything breaks
// 3. How do you rollback?
// - Git revert + push = 2 minutes
// - During those 2 minutes: system down
// - All incoming calls dropped ‚ùå
```

**What Happens:**
1. New code deployed at 3:00 PM
2. Code has a bug: queries 'calls' table with typo
3. All request handlers fail (500 error)
4. Load balancer still routes requests (health check says OK)
5. All customers' incoming calls fail
6. Voicemail backup not configured
7. For 10 minutes, clinic misses all calls ‚ùå

**Test Case That Will Fail:**
```bash
# Deploy with intentional bug
Push code that throws error on startup
Expected: Render detects issue, alert sent
Actual: Render keeps routing traffic, all requests fail
```

---

## CROSS-CUTTING VULNERABILITIES

### Vulnerability 1: No Rate Limiting on Webhook Endpoints

```typescript
// webhooks.ts line 57-63
const webhookLimiter = rateLimit({
  windowMs: 60 * 1000,     // 1 minute
  max: 100,                // 100 events per minute
  message: 'Too many webhook events'
});

// ‚ùå ISSUE: Vapi might send 100+ events per minute legitimately
// - Rapid call sequences
// - High-volume period (lunch hour)
// Rate limiter will drop legitimate events ‚ùå
```

### Vulnerability 2: No Circuit Breaker for Supabase

```typescript
// vapi-client.ts has circuit breaker
// But supabase doesn't
//
// If Supabase is down:
// - Every API call tries to connect
// - Every call waits 10+ seconds
// - All request handlers block
// - WebSocket clients disconnect
// - Dashboard becomes unusable ‚ùå
```

### Vulnerability 3: Logging Might Expose Sensitive Data

```typescript
// If call content is logged:
// "Customer asked about post-BBL care"
// This could be PII ‚ùå
//
// If webhook body is logged:
// Might include customer phone number ‚ùå
```

### Vulnerability 4: No Metrics/Alerts

```typescript
// CEO briefing says: "No Sentry, DataDog"
//
// So when:
// - 10% of calls fail silently
// - Recording uploads stuck
// - Database disk space running low
// No one knows ‚ùå
//
// You find out when customer complains a week later
```

---

## STRESS TEST SCENARIOS

### Scenario 1: Sudden Traffic Spike
```
Initial: 10 concurrent calls
Sudden: 100 concurrent calls (clinic happy hour special)

What breaks:
- Embedding API rate limited (429 errors)
- WebSocket buffer overflows
- Database connection pool exhausted
- Render CPU hits 100%, requests timeout

Recovery: 30+ minutes (if automatic scaling isn't configured)
Data loss: 20-30 calls dropped/orphaned
```

### Scenario 2: Cascading Failure
```
Failure 1: OpenAI API down
- RAG context fails to embed
- System continues but KB doesn't work
- Customers get generic responses

Failure 2: Supabase down
- Call recordings can't upload
- Recordings pile up in queue
- Queue runs out of memory

Failure 3: Both recover, but out of sync
- 1000 pending recordings to upload
- All try uploading simultaneously
- Network congestion
- Some uploads fail permanently

Recovery: Manual intervention needed
```

### Scenario 3: Memory Leak
```
Condition: Dashboard open 24/7 with auto-refresh
After 1 hour: WebSocket buffer = 100MB
After 4 hours: Node.js memory = 1GB
After 8 hours: Node.js heap overflow, process crashes

Recovery: Manual restart, all WebSocket clients disconnected
User impact: All dashboard users logged out
```

### Scenario 4: Database Index Missing
```
Clinic has 10,000 calls in database
User filters by date: "Show calls from last 30 days"
Database query: SELECT * FROM calls WHERE org_id = ... AND date >= ...
No index on (org_id, date)
Query scans all 10,000 rows
Response time: 45 seconds (timeout)

User clicks refresh
Another query starts
Database CPU hits 100%
All other queries slow down
System becomes unusable
```

---

## KNOWN OUTSTANDING ISSUES

```
Found in code comments:
‚ùå recording-metrics-monitor.ts: "TODO: Send alert to monitoring service"
‚ùå integrations.ts: "TODO: Encrypt this in production"
‚ùå phone-numbers.ts: "TODO: Use secrets manager in production"

These are NOT TODO, they're REQUIRED for production
```

---

## RISK SEVERITY MATRIX

| Component | Load Test | Failure Mode | Impact | Time to Fix |
|-----------|-----------|--------------|--------|-------------|
| Embeddings (OpenAI) | 50 chunks | Rate limited (429) | KB broken | 1-2 hours |
| WebSocket | 100 connections | Buffer overflow | Dashboard frozen | 30 mins |
| Recording Upload | 20 concurrent | Supabase 5xx | Orphaned recordings | 2-4 hours |
| Database Query | 10K rows | Missing index | Timeout (45s) | 5 mins (add index) |
| Vapi Integration | Circuit breaker | 5 failures | System unavailable | 1 hour |
| Auth | Dev bypass | Unauthorized access | Data leak | 5 mins |
| Deployment | Bad code | 500 error | Clinic downtime | 10 mins (rollback) |

---

## WHAT TO TEST BEFORE LAUNCH

**CRITICAL (Must Pass):**
- [ ] 10 concurrent calls without dropping
- [ ] Recording upload retry on network failure
- [ ] WebSocket reconnect after 5+ minute outage
- [ ] OpenAI rate limiting with fallback
- [ ] Authentication cannot be bypassed without valid token
- [ ] Escalation works for ambiguous queries (not just keywords)

**IMPORTANT (Should Pass):**
- [ ] 100 calls in database query in <5 seconds
- [ ] Dashboard updates all 100 users within 2 seconds of call
- [ ] Large document upload (10MB) doesn't timeout
- [ ] Vapi circuit breaker recovers after 1 minute
- [ ] Failed recording uploads retry automatically

**NICE TO HAVE (Can Do Later):**
- [ ] Load test with 1000 concurrent calls
- [ ] Performance test with 100K calls in database
- [ ] Penetration test for security vulnerabilities
- [ ] Chaos testing (random service failures)

---

## BOTTOM LINE

**This MVP will work for:**
- 5-20 concurrent calls ‚úÖ
- Small KB (< 50 documents) ‚úÖ
- One clinic using the system ‚úÖ
- Normal network conditions ‚úÖ

**This MVP will FAIL for:**
- 50+ concurrent calls ‚ùå
- Large documents (> 1MB) ‚ùå
- Multiple clinics simultaneously ‚ùå
- Network issues (dropped packets) ‚ùå
- High volume periods ‚ùå

**You need to fix these BEFORE claiming "production-ready":**
1. Add database indexes
2. Implement circuit breaker for Supabase
3. Add heartbeat/ping to WebSocket
4. Set up error monitoring (Sentry)
5. Test with real concurrent load (at least 10 calls)
6. Verify Vapi escalation works (not just keywords)
7. Remove dev-mode auth bypass from production
8. Add recording cleanup job
9. Implement token refresh mechanism
10. Document rollback procedure

**Current Status:** Code-complete, stress-test-incomplete, production-unready.

---

**Ready to actually test, or just keep hoping? üî•**
